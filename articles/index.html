<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
       
      <meta name="keywords" content="数据科学" />
       
      <meta name="description" content="面向图数据的人工智能研究" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>学术论文 |  图数据科学实验室</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="../dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="../css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-103389953-1', 'auto');
ga('send', 'pageview');

</script>


 
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?8e2e80642e4c93347fbaa1e33f7017b9";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <script src="https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js"></script>
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link rel="alternate" href="atom.xml" title="图数据科学实验室" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="page-"
  class="article article-type-page"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  学术论文
</h1>
 

      
    </header>
       
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="2025-年"><a class="markdownIt-Anchor" href="#2025-年"></a> 2025 年</h2>
<p>[1] Sun Junding, Xue  Jianxiang,  Xu  Zhaozhao, Li Ningshu,Tang Chaosheng ,  Zhao Lei, Pu Bin, Zhang Yu-Dong. Multi-Scale Feature Attention-DEtection TRansformer: Multi-Scale Feature Attention for security check object detection[J]. Biomedical Signal Processing and Control, 2025(106): 107634 . (WOS:001428766400001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.bspc.2025.107634">https://doi.org/10.1016/j.bspc.2025.107634</a>, 中科院 2 区, 影响因子: 4.9, Accession number: 20250717883373, ISSN: 1751-9640, 发表时间: 2025 年 2 月 17 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>[2] Yan Yidan, Sun Junding, Zhang Hongyuan, Tang Chaosheng , Wu Xiaosheng ,  Zhang Yu-Dong. DCMA-Net: A dual channel multi-scale feature attention network for crack image segmentation[J], Engineering Applications of Artificial Intelligence. 2025(148): 110411, (WOS: ,  <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.engappai.2025.110411">https://doi.org/10.1016/j.engappai.2025.110411</a>, 中科院 1区, TOP期刊, 影响因子: 8.0, Accession number: 20250717883373, ISSN:  0952-1976, 发表时间: 2025 年 3月 17 日)<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p>[3] <strong>Tang Chaosheng</strong>, Song Jiahao, Xu  Zhaozhao, Junding Sun, Wang Shuihua, Zhang Yu-Dong. Residual n-hop omnipresent-attention graph convolution network for brain tumor diagnosis[J]. Biomedical Signal Processing and Control, 2026, 112: 108537.  (WOS:  , <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.bspc.2025.108537">https://doi.org/10.1016/j.bspc.2025.108537</a>, 中科院 2 区, 影响因子: 5.1, Accession number:  20253318970304 , ISSN: 1746-8094, 发表时间: 2025 年 8 月 13 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:2">[1:2]</a></sup> <sup class="footnote-ref"><a href="#fn2" id="fnref2:1">[2:1]</a></sup></p>
<h2 id="2024-年"><a class="markdownIt-Anchor" href="#2024-年"></a> 2024 年</h2>
<p>[1] Sima Haifeng, Chen Bailiang, <strong>Tang Chaosheng</strong> , Zhang Yu-Dong, Sun Junding. Multi-Scale Feature Attention-DEtection TRansformer: Multi-Scale Feature Attention for security check object detection[J]. IET Computer Vision, 2024: 1-13. (WOS:001142805400001, <a target="_blank" rel="noopener" href="https://doi.org/10.1049/cvi2.12267">https://doi.org/10.1049/cvi2.12267</a>, 中科院 4 区, 影响因子: 1.7, Accession number: 20240315403652, ISSN: 1751-9640, 发表时间: 2024 年 1 月 16 日)</p>
<p>[2] Sun Junding, Ming Hu, Xiaosheng Wu, Tang Chaosheng , Husam Lahza, Wang Shuihua, Zhang Yu-Dong. MVSI-Net: Multi-View Attention and Multi-Scale Feature Interaction for Brain Tumor Segmentation[J], Biomedical Signal Processing and Control, 2024,95: 106484 ( WOS:001246269000001, https://doi:10.1016/j.bspc.2024.106484, 中科院 2 区, 影响因子: 5.1, Accession number:20242216159856, ISSN: 1746-8094, 发表时间: 2024 年 5 月 25 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:3">[1:3]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup></p>
<p>[3] Xu Zhaozhao, Fangyuan Yang, Tang Chaosheng, Hong Wang, Wang Shuihua, Junding Sun, Zhang Yu-Dong. FG-HFS: A Feature Filter and Group Evolution Hybrid Feature Selection Algorithm for High-Dimensional Gene Expression Data[J], Expert Systems with Applications, 2024,245: 123069 (WOS:001157078000001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.eswa.2023.123069">https://doi.org/10.1016/j.eswa.2023.123069</a>, 中科院 1 区, <strong>TOP 期刊</strong>, 影响因子: 8.5, Accession number: 20240415436755, ISSN: 0957-4174, 发表时间: 2024 年 2 月 24 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:4">[1:4]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:1">[4:1]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:2">[3:2]</a></sup></p>
<p>[4] <strong>Tang Chaosheng</strong>, Xi Mengbo, Junding Sun, Wang Shuihua, Zhang Yu-Dong. MACFNet: Detection of Alzheimer’s Disease via Multiscale Attention and Cross-Enhancement Fusion Network[J], Computer Methods and Programs in Biomedicine, 2024, 254: 108259 (WOS:001254325100001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cmpb.2024.108259">https://doi.org/10.1016/j.cmpb.2024.108259</a>, 中科院 2 区, <strong>TOP 期刊</strong>, 影响因子: 6.1, Accession number: 20242416249801, ISSN: 0169-2607, 发表时间: 2024 年 6 月 12 日，出版时间:2024 年 9 月) <sup class="footnote-ref"><a href="#fn1" id="fnref1:5">[1:5]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:2">[4:2]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:3">[3:3]</a></sup></p>
<p>[5] <strong>Tang Chaosheng</strong>, Zhou Feifei, Junding Sun, Zhang Yu-Dong. Lung-YOLO: Multiscale feature fusion attention and cross-layer aggregation for lung nodule detection[J], Biomedical Signal Processing and Control. 2025, 99: 106815. (WOS:001314843800001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.bspc.2024.106815">https://doi.org/10.1016/j.bspc.2024.106815</a>, 中科院 2 区, 影响因子: 5.1, Accession number: 20243717033280, ISSN: 1746-8094, 发表时间: 2024 年 9 月 11 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:6">[1:6]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:4">[3:4]</a></sup></p>
<p>[6] <strong>Tang Chaosheng</strong>, Zhi Xinke, Junding Sun, Wang Shuihua, Zhang Yu-Dong. TGPO-WRHNN: Two-stage Grad-CAM-guided PMRS Optimization and weighted-residual hypergraph neural network for pneumonia detection[J]. Knowledge-Based Systems. 2024, 306:112708 (WOS: 001357025000001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.knosys.2024.112708">https://doi.org/10.1016/j.knosys.2024.112708</a>, 中科院 1 区, <strong>TOP 期刊</strong>, 影响因子: 7.2, Accession number: 20244617350824, ISSN: 0950-7051 , 发表时间: 2024 年 11 月 09 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:7">[1:7]</a></sup> <sup class="footnote-ref"><a href="#fn2" id="fnref2:2">[2:2]</a></sup></p>
<p>[7] <strong>Tang Chaosheng</strong>, Xu Wenle, Sun Junding, Wang Shuihua，Zhang Yudong, Górriz, Juan Manuel. Multi-graph Networks with Graph Pooling for COVID-19 Diagnosis[J]. Journal of Bionic Engineering, 2024, 21(6): 3179-3200. (WOS: 001357669000001, <a target="_blank" rel="noopener" href="https://doi.org/10.1007/s42235-024-00600-9">https://doi.org/10.1007/s42235-024-00600-9</a>, 中科院 3 区, 影响因子: 4.9, Accession number: 20244717396416, ISSN: 1672-6529 , 发表时间: 2024 年 11 月 18 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:8">[1:8]</a></sup> <sup class="footnote-ref"><a href="#fn2" id="fnref2:3">[2:3]</a></sup></p>
<p>[8] <strong>Tang Chaosheng</strong>, Zhou Feifei, Junding Sun, Zhang Yu-Dong. Circle-YOLO: an anchor-free lung nodule detection algorithm using bounding circle representation[J], Pattern Recognition. 2025, 161:111294. (WOS: 001394720800001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.patcog.2024.111294">https://doi.org/10.1016/j.patcog.2024.111294</a>, 中科院 1 区, <strong>TOP 期刊</strong>, 影响因子: 7.5, Accession number: 20245217569950, ISSN: 0031-3203, 发表时间: 2024 年 12 月 16 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:9">[1:9]</a></sup> <sup class="footnote-ref"><a href="#fn2" id="fnref2:4">[2:4]</a></sup></p>
<p>[9] Sun Junding, Li Yabei, Wu Xiaosheng, Tang Chaosheng , Wang Shuihua, Zhang Yu-Dong. HAD-Net: An attention U-based network with hyper-scale shifted aggregating and max-diagonal sampling for medical image segmentation[J]. Computer Vision and Image Understanding. 2024, 249:10415. (WOS:001316845400001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cviu.2024.104151">https://doi.org/10.1016/j.cviu.2024.104151</a>, 中科院 3 区, 影响因子:4.3, Accession number: 20243817045736, ISSN: 1077-3142, 发表时间: 2024 年 9 月 7 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:10">[1:10]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:3">[4:3]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:5">[3:5]</a></sup></p>
<p>[10] Sun Junding, Wang Biao, Wu Xiaosheng, Tang Chaosheng , Wang Shuihua, Zhang Yu-Dong. MAPFUNet: Multi-attention Perception-Fusion U-Net for Liver Tumor Segmentation[J]. Journal of Bionic Engineering. 2024,21:2515–2539 . (WOS: 001249435000002, <a target="_blank" rel="noopener" href="https://doi.org/10.1007/s42235-024-00562-y">https://doi.org/10.1007/s42235-024-00562-y</a>, 中科院 3 区, 影响因子:4.9, Accession number: 20242516285722, ISSN: 1672-6529, 发表时间: 2024 年 6 月 18 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:11">[1:11]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:4">[4:4]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:6">[3:6]</a></sup></p>
<p>[11] Xiaosheng Wu, Hang Zhang, Junding Sun, Shuihua Wang, Yudong Zhang. YOLO-MSRF for lung nodule detection[J]. Biomedical Signal Processing and Control, 2024, 94: 106318. (WOS:001228159100001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.bspc.2024.106318">https://doi.org/10.1016/j.bspc.2024.106318</a>, 中科院 2 区, 影响因子: 5.1, Accession number: 20241515905401, ISSN: 1746-8094, 发表时间: 2024 年 4 月 10 日)</p>
<p>[12] Lihong Zhang, Chongxin Xu, Yuzhuo Li, Tong Liu, Junding Sun. MCSE-U-Net: multi-convolution blocks and squeeze and excitation blocks for vessel segmentation[J]. Quantitative Imaging in Medicine and Surgery, 2024,14(3): 2426-2440. (WOS:001222015100011, <a target="_blank" rel="noopener" href="https://doi.org/10.21037/qims-23-1454">https://doi.org/10.21037/qims-23-1454</a>, 中科院 2 区, 影响因子:2.9, ISSN: 1939-1404, 发表时间: 2024 年 3 月 4 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:12">[1:12]</a></sup></p>
<p>[13] Chunyang Wang; Peipei Zhou; Yudong Zhang; Junding Sun; Bibo Lu; Zhaozhao Xu. GCFC: Graph Convolutional Fusion CNN Network for Cross-Domain Zero-Shot Extraction of Winter Wheat Map[J]. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2024, 17:9069-9089. (WOS:001224319800018, <a target="_blank" rel="noopener" href="https://doi.org/10.1109/JSTARS.2024.3392448">https://doi.org/10.1109/JSTARS.2024.3392448</a>, 中科院 2 区, 影响因子:4.7, Accession number: 20241816000286, ISSN: 1939-1404, 发表时间: 2024 年 4 月 22 日)</p>
<p>[14] Haifeng Sima, Manyang Wang, Lanlan Liu, Yudong Zhang, Junding Sun. MSO-DETR: Metric space optimization for few-shot object detection[J]. CAAI Transactions on Intelligence Technology, 2014: (WOS: 001216888100001, <a target="_blank" rel="noopener" href="https://doi.org/10.1049/cit2.12342">https://doi.org/10.1049/cit2.12342</a>, 中科院 2 区, 影响因子: 8.4, Accession number: 20241916037777, ISSN: 2468-6557, 发表时间: 2024 年 5 月 2 日)</p>
<h2 id="2023-年"><a class="markdownIt-Anchor" href="#2023-年"></a> 2023 年</h2>
<p>[1] <strong>Tang Chaosheng</strong>, Li Bin, Sun Junding, Wang Shui-Hua, Zhang Yu-Dong. GAM-SpCaNet: gradient awareness minimization-based spinal convolution attention network for brain tumor classification[J], Journal of King Saud University - Computer and Information Sciences. 2023,35(2):560-575. (WOS:001030030500001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.jksuci.2023.01.002">https://doi.org/10.1016/j.jksuci.2023.01.002</a>, 中科院 2 区, 影响因子: 6.9,ISSN: 1319-1578, 发表时间: 2023 年 1 月 10 日, 出版时间: 2023 年 2 月) <sup class="footnote-ref"><a href="#fn1" id="fnref1:13">[1:13]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:5">[4:5]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:7">[3:7]</a></sup></p>
<p>[2] 孙君顶,王金凯, 唐朝生,毋小省. 基于渐进式嵌套特征的融合网络, 模式识别与人工智能,2023,36(1):70-80.(Accession number: 20230913647612, CSCD/北大核心, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009">http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009</a>. ISSN 1003-6059, 出版时间: 2023 年 1 月) <sup class="footnote-ref"><a href="#fn1" id="fnref1:14">[1:14]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:6">[4:6]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:8">[3:8]</a></sup><br>
Sun Junding, Wang Jinkai, Tang Chaosheng, Wu Xiaosheng. Fusion Network Based on Progressive Nested Feature[J], Pattern Recognition and Artificial Intelligence. 2023,36(1):70-80.(Accession number : 20230913647612, CSCD/北大核心, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009">http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009</a>. ISSN: 1003-6059, 出版时间: 2023 年 1 月)</p>
<p>[3] Junding Sun, Zhao Jiuqiang, Wu Xiaosheng , Tang Chaosheng, Wang Shuihua, Zhang Yudong. DSGA-Net: Deeply separable gated transformer and attention strategy for medical image segmentation network[J]. Journal of King Saud University - Computer and Information Sciences. 2023,35(5):101553. (WOS:001029982400001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.jksuci.2023.04.006">https://doi.org/10.1016/j.jksuci.2023.04.006</a>, 中科院 2 区, 影响因子: 6.9, ISSN: 1319-1578, 发表时间: 2023 年 4 月 11 日, 出版时间: 2023 年 5 月) <sup class="footnote-ref"><a href="#fn1" id="fnref1:15">[1:15]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:7">[4:7]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:9">[3:9]</a></sup></p>
<p>[4] Sun Junding, Pi Pengpeng, Wu Xiaosheng , Tang Chaosheng, Wang Shuihua, Zhang Yudong. CTMLP: Can MLPs replace CNNs or transformers for COVID-19 diagnosis? [J]. Computers in Biology and Medicine, 2023, 159: 106847. (WOS:000983634600001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.compbiomed.2023.106847">https://doi.org/10.1016/j.compbiomed.2023.106847</a>, 中科院 2 区，影响因子:6.7, Accession number:20231613901030, ISSN: 0010-4825, 发表时间: 2023 年 4 月 13 日, 出版时间: 2023 年 6 月) <sup class="footnote-ref"><a href="#fn1" id="fnref1:16">[1:16]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:8">[4:8]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:10">[3:10]</a></sup></p>
<p>[5] <strong>Tang Chaosheng</strong>, Wei Mingyang, Sun Junding, Wang Shui-Hua, Zhang Yu-Dong.CsAGP: Detecting Alzheimer’s Disease from Multimodal Images via Dual-Transformer with Cross-Attention and Graph Pooling[J]. Journal of King Saud University - Computer and Information Sciences. 2023,35(7): 101618 (WOS: 001090833900001, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.jksuci.2023.101618">https://doi.org/10.1016/j.jksuci.2023.101618</a>, 中科院 2 区, 影响因子: 6.9,ISSN: 1319-1578, 发表时间: 2023 年 6 月 14 日, 出版时间: 2023 年 6 月 25 日) <sup class="footnote-ref"><a href="#fn1" id="fnref1:17">[1:17]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:9">[4:9]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:11">[3:11]</a></sup></p>
<h2 id="2022-年"><a class="markdownIt-Anchor" href="#2022-年"></a> 2022 年</h2>
<p>[1] <strong>Tang Chaosheng</strong>, Hu Chaochao, Sun Junding, Wang Shui-Hua, Zhang Yu-Dong. NSCGCN: A novel deep GCN model to diagnosis COVID-19[J]. Computers in Biology and Medicine, 2022, 150: 106151. (WOS:000918334200003, <a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.compbiomed.2022.106151">https://doi.org/10.1016/j.compbiomed.2022.106151</a>, 中科院 2 区，影响因子:6.7, Accession number:20224212973201, ISSN: 0010-4825, 发表时间: 2022 年 10 月 13 日, 出版时间: 2022 年 11 月) <sup class="footnote-ref"><a href="#fn1" id="fnref1:18">[1:18]</a></sup> <sup class="footnote-ref"><a href="#fn4" id="fnref4:10">[4:10]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:12">[3:12]</a></sup></p>
<p>[2] Sun Junding, Pi Pengpeng, Tang Chaosheng, Wang Shui-Hua, Zhang Yu-Dong. TSRNet: Diagnosis of COVID-19 based on self-supervised learning and hybrid ensemble model[J]. Computers in Biology and Medicine, 2022: 105531. (WOS:000799841700002, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1016/j.compbiomed.2022.105531">http://dx.doi.org/10.1016/j.compbiomed.2022.105531</a>, 中科院 2 区，Accession number:20221812054643, 影响因子:6.7, ISSN: 0010-4825, 发表时间: 2022 年 4 月 16 日) <sup class="footnote-ref"><a href="#fn4" id="fnref4:11">[4:11]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:13">[3:13]</a></sup></p>
<p>[3] Sun Junding, Hui Zhenkun, Tang Chaosheng, Wu Xiaosheng. Liver segmentation based on complementary features U-Net[J]. Visual Computer, 2022: 1-12(WOS:000836989900002, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1007/s00371-022-02617-9">http://dx.doi.org/10.1007/s00371-022-02617-9</a>, 中科院 3 区，影响因子 2.84, Accession number: 20223212555755, ISSN: 0178-2789, 发表时间: 2022 年 8 月 7 日) <sup class="footnote-ref"><a href="#fn4" id="fnref4:12">[4:12]</a></sup></p>
<h2 id="2021-年"><a class="markdownIt-Anchor" href="#2021-年"></a> 2021 年</h2>
<p>[1] <strong>唐朝生</strong>,胡超超,孙君顶,司马海峰.医学图像深度学习技术:从卷积到图卷积的发展[J].中国图象图形学报,2021,26(9):2078-2093 (CSCD/北大核心, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.11834/jig.200666">http://dx.doi.org/10.11834/jig.200666</a>, ISSN: 1006-8961) <sup class="footnote-ref"><a href="#fn4" id="fnref4:13">[4:13]</a></sup><br>
Tang Chaosheng, Hu Chaochao, Sun Junding, Sima Haifeng. Deep learning-based medical images analysis evolved from convolution to graph convolution[J], Journal of image and Graphics, 2021,26(9):2078-209 (CSCD/北大核心,<a target="_blank" rel="noopener" href="http://dx.doi.org/10.11834/jig.200666">http://dx.doi.org/10.11834/jig.200666</a>, ISSN: 1006-8961, 发表时间: 2021 年 9 月 3 日)</p>
<p>[2] Sun Junding, Li Xiang, Tang Chaosheng(第 1 通讯作者), Chen Shixin. BEVGGC: Biogeography-Based Optimization Expert-VGG for Diagnosis COVID-19 via Chest X-ray Images[J]. Computer Modeling in Engineering &amp; Sciences, 2021, 129(2): 729-753. (WOS:000706698100007, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.32604/cmes.2021.016416">http://dx.doi.org/10.32604/cmes.2021.016416</a>, 中科院 4 区, 影响因子: 2.03, Accession number: 20214211024804, ISSN: 1526-1492, 发表时间: 2021 年 10 月 26 日) <sup class="footnote-ref"><a href="#fn4" id="fnref4:14">[4:14]</a></sup></p>
<p>[3] Sun Junding, Li Xiang, Tang Chaosheng(第 1 通讯作者), Wang Shui-Hua, Zhang Yu-Dong. MFBCNNC: Momentum factor biogeography convolutional neural network for COVID-19 detection via chest X-ray images[J]. Knowledge-Based Systems, 2021, 232: 107494.( WOS:000703550700002, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1016/j.knosys.2021.107494">http://dx.doi.org/10.1016/j.knosys.2021.107494</a>, 中科院 1 区，<strong>TOP 期刊</strong>, 影响因子 7.84, ISSN: 0950-7051, 发表时间: 2021 年 11 月 28 日) <sup class="footnote-ref"><a href="#fn4" id="fnref4:15">[4:15]</a></sup></p>
<p>[4] 孙君顶,惠朕堃,唐朝生,毋小省. 基于 U-Net 的特征交互分割方法[J].模式识别与人工智能,2021,34(11):1058-1068.(Accession number: 20215011303204 , CSCD/北大核心, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009">http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009</a>. ISSN: 1003-6059, 发表时间: 2021 年 11 月 30 日) <sup class="footnote-ref"><a href="#fn4" id="fnref4:16">[4:16]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:14">[3:14]</a></sup><br>
Sun Junding, Hui Zhenkun, Tang Chaosheng, Wu Xiaosheng. U-Net Based Feature Interaction Segmentation Method[J], Pattern Recognition and Artificial Intelligence. 2021,34(11):1058-1068.(Accession number : 20215011303204, CSCD/北大核心, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009">http://dx.doi.org/10.16451/j.cnki.issn1003-6059.202111009</a>. ISSN 1003-6059, 发表时间: 2021 年 11 月 30 日)</p>
<h2 id="2020-年"><a class="markdownIt-Anchor" href="#2020-年"></a> 2020 年</h2>
<p>[1] <strong>Tang Chaosheng</strong>, Nayak Deepak Ranjan, Wang, Shuihua. Least-Square Support Vector Machine and Wavelet Selection for Hearing Loss Identification[J]. Computer Modeling in Engineering &amp; Sciences, 2020, 125(1): 299-313.( WOS:000573973000003, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.32604/cmes.2020.011069">http://dx.doi.org/10.32604/cmes.2020.011069</a>, 中科院 4 区，影响因子:2.03, Accession number: 20203909239864, ISSN: 1526-1492)</p>
<p>[2] Chen Ning, Ma Yingchao, Tang Chaosheng, Chen An, Yao Xiaohui. Risk assessment and comparison of regional natural disasters in China using clustering[J]. Intelligent Decision Technologies, 2020, 14(3): 349-357. (Accession number: 20204309382673, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.3233/IDT-190086">http://dx.doi.org/10.3233/IDT-190086</a>, ISSN: 1872-4981)</p>
<p>[3] Wang Shuihua, Wu Xiaosheng, Zhang Yu-Dong, Tang Chaosheng, Xin Zhang. Diagnosis of COVID-19 by wavelet Renyi entropy and three-segment biogeography-based optimization[J], International Journal of Computational Intelligence Systems. 2020,13(1): 1332-1344. (WOS:000608285000001, <a target="_blank" rel="noopener" href="https://doi.org/10.2991/ijcis.d.200828.001">https://doi.org/10.2991/ijcis.d.200828.001</a>, 中科院 4 区，影响因子:2.244, ISSN: 1875-6891)</p>
<h2 id="2019-年"><a class="markdownIt-Anchor" href="#2019-年"></a> 2019 年</h2>
<p>[1] Wang Shui-Hua, Xie Shipeng, Chen, Xianqing, Guttery, David S., Tang Chaosheng(第 1 通讯作者), Sun Junding, Zhang Yu-Dong. Alcoholism Identification Based on an AlexNet Transfer Learning Model[J]. Frontiers in Psychiatry, 2019, 10:205(WOS:000464405100003, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.3389/fpsyt.2019.00205">http://dx.doi.org/10.3389/fpsyt.2019.00205</a>, <strong>ESI 高被引论文</strong>, 中科院 3 区, 影响因子: 5.44)</p>
<p>[2] Wang Shuihua, Tang Chaosheng, Sun Junding, Zhang Yudong. Cerebral Micro-Bleeding Detection Based on Densely Connected Neural Network[J]. Frontiers in Neuroscience, 2019, 13: 422. (WOS:000468180500001, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.3389/fnins.2019.00422">http://dx.doi.org/10.3389/fnins.2019.00422</a>, 中科院 2 区, 影响因子: 5.15)</p>
<p>[3] Zhang Yu-Dong, Govindaraj, Vishnu Varthanan, Tang Chaosheng, Zhu, Weiguo, Sun Junding. High Performance Multiple Sclerosis Classification by Data Augmentation and AlexNet Transfer Learning Model[J]. Journal of Medical Imaging and Health informatics, 2019, 9(9): 2012-2021. (WOS:000483964900035, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1166/jmihi.2019.2692">http://dx.doi.org/10.1166/jmihi.2019.2692</a>, 中科院 4 区, 影响因子:1.7, ISSN: 2156-7018)</p>
<p>[4] Chen Ning, Ribeiro Bernardete, Chen An, Tang Chaosheng. Optimization of selective ensemble for cost-sensitive classification: An empirical study[J]. Intelligent Decision Technologies, 2019, 12(4): 399-410. (Accession number: 20190306397778, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.3233/IDT-180344">http://dx.doi.org/10.3233/IDT-180344</a>, ISSN: 1872-4981)</p>
<p>[5] Chen Ning, Chen, Lu, Tang Chaosheng, Wu Zhengjiang, Chen An. Disaster risk evaluation using factor analysis: a case study of Chinese regions[J]. Natural Hazards, 2019, 99(1): 321-335. (WOS:000489750300015, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1007/s11069-019-03742-w">http://dx.doi.org/10.1007/s11069-019-03742-w</a>, 中科院 3 区, 影响因子: 3.16, ISSN: 0921-030X)</p>
<p>[6] Chen Ning, Ribeiro Bernardete, Tang Chaosheng, Chen An. Multi-label learning vector quantization for semi-supervised classification[J]. Intelligent Data Analysis, 2019, 23(4): 839-853. ( WOS:000488816000007, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.3233/IDA-184195">http://dx.doi.org/10.3233/IDA-184195</a>, 中科院 4 区，影响因子 0.894, Accession number: 20194207529485, ISSN: 0950-7051)</p>
<h2 id="2018-年"><a class="markdownIt-Anchor" href="#2018-年"></a> 2018 年</h2>
<p>[1] Wang Shui-Hua, Tang Chaosheng, Sun Junding, Yang Jingyuan, Huang Chenxi, Phillips Preetha, Zhang Yu-Dong. Multiple Sclerosis Identification by 14-Layer Convolutional Neural Network With Batch Normalization, Dropout, and Stochastic Pooling[J]. Frontiers in neuroscience, 2018, 12: 818. (WOS:000449565600001, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.3389/fnins.2018.00818">http://dx.doi.org/10.3389/fnins.2018.00818</a>, 中科院 2 区, 影响因子: 5.15)</p>
<p>[2] Zhang Yu-Dong, Pan Chichun, Sun Junding, <strong>Tang Chaosheng(通讯作者)</strong>. Multiple sclerosis identification by convolutional neural network with dropout and parametric ReLU[J]. Journal of Computational Science, 2018, 28: 1-10. (WOS:000449242900001, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1016/j.jocs.2018.07.003">http://dx.doi.org/10.1016/j.jocs.2018.07.003</a>, 中科院 3 区, 影响因子:3.483)</p>
<p>[3] Zhang Yu-Dong, Muhammad, Khan, <strong>Tang Chaosheng(通讯作者)</strong>. Twelve-layer deep convolutional neural network with stochastic pooling for tea category classification on GPU platform[J]. Multimedia Tools and Applications, 2018, 77(17): 22821-22839. (WOS:000441364500056, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1007/s11042-018-5765-3">http://dx.doi.org/10.1007/s11042-018-5765-3</a>, 中科院 3 区，影响因子:2.517, Accession number: 20180904846927, ISSN: 1380-7501)</p>
<p>[4] Zhang, Xiaohong, Jiang, Yulin, Ren, Jianji, <strong>Tang Chaosheng(通讯作者)</strong>. A label propagation approach based on local optimization[J]. International Journal of Modern Physics C, 2018, 29(06): 1850047.( WOS:000437316200008, <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1142/S012918311850047X">http://dx.doi.org/10.1142/S012918311850047X</a>, 中科院 4 区, 影响因子: 1.35, ISSN: 0129-1831)</p>
<h1 id="会议论文"><a class="markdownIt-Anchor" href="#会议论文"></a> 会议论文</h1>
<p>[1] Tang Chaosheng, Lee Elizabeth. Hearing loss identification via wavelet entropy and combination of Tabu search and particle swarm optimization[C]， 2018 IEEE 23rd International Conference on Digital Signal Processing (DSP).Shanghai, China: Institute of Electrical and Electronics Engineers Inc., 2018: 1-5. (<a target="_blank" rel="noopener" href="https://doi.org/10.1109/ICDSP.2018.8631839">https://doi.org/10.1109/ICDSP.2018.8631839</a>, 检索类型: 会议论文 CA, Accession number: 20191106629479)</p>
<p>[2] Tang Chaosheng, Li Bin, Sun Junding. BraDect: A Novel Brain Tumor Image Classification Algorithm[C]. 11th International Conference on Networks, Communication and Computing, ICNCC 2022,Beijing, China: Association for Computing Machinery, 2022: 12-17.(<a target="_blank" rel="noopener" href="https://doi.org/10.1145/3579895.3579898">https://doi.org/10.1145/3579895.3579898</a>, 检索类型: 会议论文 CA, Accession number: 20231714010957) <sup class="footnote-ref"><a href="#fn4" id="fnref4:17">[4:17]</a></sup> <sup class="footnote-ref"><a href="#fn3" id="fnref3:15">[3:15]</a></sup></p>
<p><strong>项目资助</strong></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>国家自然科学基金面上项目: 基于多模态特征重构的医学图像深度图卷积神经网络分类算法研究(62276092) <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a> <a href="#fnref1:2" class="footnote-backref">↩︎</a> <a href="#fnref1:3" class="footnote-backref">↩︎</a> <a href="#fnref1:4" class="footnote-backref">↩︎</a> <a href="#fnref1:5" class="footnote-backref">↩︎</a> <a href="#fnref1:6" class="footnote-backref">↩︎</a> <a href="#fnref1:7" class="footnote-backref">↩︎</a> <a href="#fnref1:8" class="footnote-backref">↩︎</a> <a href="#fnref1:9" class="footnote-backref">↩︎</a> <a href="#fnref1:10" class="footnote-backref">↩︎</a> <a href="#fnref1:11" class="footnote-backref">↩︎</a> <a href="#fnref1:12" class="footnote-backref">↩︎</a> <a href="#fnref1:13" class="footnote-backref">↩︎</a> <a href="#fnref1:14" class="footnote-backref">↩︎</a> <a href="#fnref1:15" class="footnote-backref">↩︎</a> <a href="#fnref1:16" class="footnote-backref">↩︎</a> <a href="#fnref1:17" class="footnote-backref">↩︎</a> <a href="#fnref1:18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>河南省高等学校重点科研项目: 基于多模态特征理解的医学图像深度学习分类算法研究(25A520009) <a href="#fnref2" class="footnote-backref">↩︎</a> <a href="#fnref2:1" class="footnote-backref">↩︎</a> <a href="#fnref2:2" class="footnote-backref">↩︎</a> <a href="#fnref2:3" class="footnote-backref">↩︎</a> <a href="#fnref2:4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>河南省高等学校重点科研项目: 基于图神经网络的多模态医学图像分类技术研究(22A520027) <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a> <a href="#fnref3:2" class="footnote-backref">↩︎</a> <a href="#fnref3:3" class="footnote-backref">↩︎</a> <a href="#fnref3:4" class="footnote-backref">↩︎</a> <a href="#fnref3:5" class="footnote-backref">↩︎</a> <a href="#fnref3:6" class="footnote-backref">↩︎</a> <a href="#fnref3:7" class="footnote-backref">↩︎</a> <a href="#fnref3:8" class="footnote-backref">↩︎</a> <a href="#fnref3:9" class="footnote-backref">↩︎</a> <a href="#fnref3:10" class="footnote-backref">↩︎</a> <a href="#fnref3:11" class="footnote-backref">↩︎</a> <a href="#fnref3:12" class="footnote-backref">↩︎</a> <a href="#fnref3:13" class="footnote-backref">↩︎</a> <a href="#fnref3:14" class="footnote-backref">↩︎</a> <a href="#fnref3:15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>河南省科技攻关项目: 基于深度学习的病理图像检测优化技术研究(212102310084) <a href="#fnref4" class="footnote-backref">↩︎</a> <a href="#fnref4:1" class="footnote-backref">↩︎</a> <a href="#fnref4:2" class="footnote-backref">↩︎</a> <a href="#fnref4:3" class="footnote-backref">↩︎</a> <a href="#fnref4:4" class="footnote-backref">↩︎</a> <a href="#fnref4:5" class="footnote-backref">↩︎</a> <a href="#fnref4:6" class="footnote-backref">↩︎</a> <a href="#fnref4:7" class="footnote-backref">↩︎</a> <a href="#fnref4:8" class="footnote-backref">↩︎</a> <a href="#fnref4:9" class="footnote-backref">↩︎</a> <a href="#fnref4:10" class="footnote-backref">↩︎</a> <a href="#fnref4:11" class="footnote-backref">↩︎</a> <a href="#fnref4:12" class="footnote-backref">↩︎</a> <a href="#fnref4:13" class="footnote-backref">↩︎</a> <a href="#fnref4:14" class="footnote-backref">↩︎</a> <a href="#fnref4:15" class="footnote-backref">↩︎</a> <a href="#fnref4:16" class="footnote-backref">↩︎</a> <a href="#fnref4:17" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://tcsds.github.io/articles/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
    </footer>
  </div>

   
   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "U0I96P0Wt6FGcfboCjpouXE7-gzGzoHsz",
    app_key: "oNYyWjG0vf67jnY7BjKw7kYm",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
    
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2017-2025
        <i class="ri-heart-fill heart_icon"></i> 善良的右行
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src=''></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="../index.html"><img src="/images/ayer2.png" alt="图数据科学实验室"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="../news">新闻</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../index.html">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../projects">项目</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../articles">论文</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../prizes">获奖</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../competition">竞赛</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../aboutme">团队</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="../tags">标签</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="../atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="../images/zhifubao.png">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="../images/weixin.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="../js/jquery-3.6.0.min.js"></script>
 
<script src="../js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="../dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->
 
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
        
    
 
<!-- busuanzi  -->
 
<script src="../js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="../css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="86"
        src="//music.163.com/outchain/player?type=2&id=28907016&auto=1&height=66"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
</body>

</html>